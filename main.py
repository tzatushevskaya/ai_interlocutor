import argparse
import functools
import json
import logging
import wave
from logging import Logger
from pathlib import Path

import colorlog
import pygame
import speech_recognition as sr
from gtts import gTTS
from pydub import AudioSegment
from transformers import GPT2LMHeadModel, GPT2Tokenizer

logger: Logger = None


class JSONFormatter(logging.Formatter):
    def format(self, record):
        log_record = {
            "timestamp": self.formatTime(record),
            "level": record.levelname,
            "message": record.getMessage(),
            "module": record.module,
            "funcName": record.funcName,
            "lineNo": record.lineno,
        }
        return json.dumps(log_record)


def setup_logger(style=None, filename=None, json_formatter=False):
    # Create a logger, use the LOGGING_LEVEL environment variable to change the logging level
    logging.basicConfig(level=logging.INFO, filename=filename)
    configured_logger: Logger = logging.getLogger(__name__)
    configured_logger.setLevel(logging.INFO)

    # Create a formatter
    color_formatter = colorlog.ColoredFormatter(
        (
            "%(white)s%(asctime)s - [%(cyan)s%(levelname)s%(reset)s]"
            "[%(green)s%(filename)s%(reset)s:"
            "%(yellow)s%(funcName)s:%(purple)s%(lineno)s%(reset)s] %(message)s"
        )
    )
    formatter = logging.Formatter(
        "%(asctime)s - [%(levelname)s][%(filename)s:%(funcName)s:%(lineno)s] %(message)s"
    )

    # Create a handler
    handler = logging.StreamHandler()
    handler.setFormatter(formatter)
    if style and style == "color":
        handler.setFormatter(color_formatter)

    # Add the handler to the logger
    configured_logger.addHandler(handler)
    configured_logger.propagate = False

    if json_formatter:
        log_json_handler = logging.FileHandler(filename, mode="a")
        json_formatter = JSONFormatter()
        log_json_handler.setFormatter(json_formatter)
        configured_logger.addHandler(log_json_handler)

    return configured_logger


def handle_errors(func):
    @functools.wraps(func)
    def wrapper(*args, **kwargs):
        try:
            return func(*args, **kwargs)
        except Exception as e:
            logger.error(f"An error occurred in {func.__name__}: {e}")
            return None

    return wrapper


@handle_errors
def convert_speech_to_text(audio_file):
    """
    Convert speech from an audio file to text using Google's Speech Recognition.

    Parameters:
    - audio_file (str): Path to the input audio file.

    Returns:
    - str: The recognized text.
    """
    recognizer = sr.Recognizer()
    with sr.AudioFile(audio_file) as source:
        audio_data = recognizer.record(source)
        text = recognizer.recognize_google(audio_data)
        return text


@handle_errors
def process_text_through_gpt(text):
    """
    Process the given text through a preconfigured GPT model.

    Parameters:
    - text (str): The input text to process.

    Returns:
    - str: The processed text generated by the GPT model.
    """
    tokenizer = GPT2Tokenizer.from_pretrained("gpt2-medium")
    model = GPT2LMHeadModel.from_pretrained("gpt2-medium")
    input_ids = tokenizer.encode(text, return_tensors="pt")
    output = model.generate(input_ids, max_length=100, num_return_sequences=1)
    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)
    return generated_text


@handle_errors
def convert_text_to_speech(text):
    """
    Convert the given text to speech using Google Text-to-Speech (gTTS) library.

    Parameters:
    - text (str): The input text to convert.

    Returns:
    - gTTS: The gTTS object containing the audio data.
    """
    tts = gTTS(text=text, lang="en")
    return tts


@handle_errors
def play_audio(audio_file):
    """
    Play the audio file.

    Parameters:
    - audio_file (str): Path to the audio file to play.
    """
    pygame.mixer.init()
    pygame.mixer.music.load(audio_file)
    pygame.mixer.music.play()
    while pygame.mixer.music.get_busy():
        pygame.time.Clock().tick(10)


@handle_errors
def process_audio(audio_file):
    """
    Process the audio file.

    Parameters:
    - audio_file (str): Path to the input audio file.

    Returns:
    - str: Path to the processed audio file.
    """
    # Convert speech to text
    text = convert_speech_to_text(audio_file)

    # Process text through GPT model
    gpt_response = process_text_through_gpt(text)

    # Convert text response to speech
    tts = convert_text_to_speech(gpt_response)

    # Save text-to-speech output to a temporary file
    output_audio_file = "samples/output_audio.mp3"
    tts.save(output_audio_file)

    return output_audio_file


@handle_errors
def is_valid_audio_format(audio_file):
    """
    Check if the given audio file is in a valid format (WAV or MP3).

    Parameters:
    - audio_file (str): Path to the input audio file.

    Returns:
    - bool: True if the audio file is in a valid format, False otherwise.
    """
    if str(audio_file).endswith(".wav"):
        try:
            with wave.open(str(audio_file), "rb") as f:
                return True
        except wave.Error:
            return False
    elif str(audio_file).endswith(".mp3"):
        try:
            AudioSegment.from_mp3(str(audio_file))
            return True
        except Exception:
            return False
    else:
        return False


@handle_errors
def process_audio(input_audio_file):
    """
    Main function to process the input audio file.

    Parameters:
    - input_audio_file (str): Path to the input audio file.

    """
    # Validate audio file format
    if not is_valid_audio_format(input_audio_file):
        error_message = "Error: Unsupported audio file format. Please provide a WAV or MP3 audio file."
        print(error_message)
        logger.error(error_message)
        return

    # Process audio
    output_audio_file = process_audio(input_audio_file)

    # Play the resulting audio
    logger.info("Playing the resulting audio...")
    play_audio(output_audio_file)

    # Check the response in the audio file:
    response = convert_speech_to_text(output_audio_file)
    logger.info(f'The obtained response is "{response}".')

    # Clean up temporary files
    Path(output_audio_file).unlink()
    print("The task is completed.")


def run():
    """Runs stages of audio processing in the conceived order,
    possibly with parameters."""

    # Setup logger
    global logger
    # current_timestamp: str = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
    # folder_run: str = f"run_at_{current_timestamp}"
    # local_log_file = Path(f"./{folder_run}_logs.json")
    local_log_file = Path("./log.json")
    logger = setup_logger(filename=local_log_file, json_formatter=True)

    parser = argparse.ArgumentParser(description="AI Interlocutor")

    parser.add_argument(
        "--file",
        "-f",
        type=str,
        default=Path("./samples/output_audio.mp3"),
        help="\tPath to audio file to process."
        "The default value is test sample audio file.",
    )
    parser.add_argument(
        "--interactive",
        "-i",
        action="store_true",
        help="Run the program in the interactive mode.",
    )

    args = parser.parse_args()
    is_interactive = True if args.interactive else False
    input_file = (
        input(
            "Please enter the path to the audio file you want to process (wav or mp3):"
        )
        if is_interactive
        else Path(args.file)
    )
    process_audio(input_file)
